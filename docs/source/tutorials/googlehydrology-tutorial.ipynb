{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJ9-UmsEzKiZ"
   },
   "source": [
    "# GoogleHydrology Finetuning Tutorial Notebook\n",
    "\n",
    "This notebook loads test results from a **base model** and a corresponding **fine-tuned model** run. It follows a specific workflow to compare their performance:\n",
    "\n",
    "1. **Configuration:** Set all necessary local paths.\n",
    "2. **Base Model**\n",
    "    * **Choose Base Model:** Interactively choose a base model from available model runs in your run directory.\n",
    "    * **Visualize Experiment:** Read the base model's `config.yml` to find and plot the train/test basins on a map.\n",
    "    * **Analyze Base Model:** Load `test_results.p` from the basemodel run directory. Calculate metrics for the base model and create a map color-coded by skill metric.\n",
    "3.  **Fine-Tuning**\n",
    "    * **Choose Basin for Fine-Tuning:** From basemodel results, choose a test basin to finetune for. Generate the config file and run command for finetuning.\n",
    "    * **Analyze Fine-Tuned Model:**  Interactively choose a fine-tuned model from available experiments. Load `test_results.p` from both the fine-tuned run directories. Calculate metrics.\n",
    "4. **Compare Models (Skill):** Use an interactive plot to compare a metric vs. lead time for the base and fine-tuned models on the target basin.\n",
    "5. **Compare Models (Hydrograph):** Use an interactive plot to compare the hydrographs (Observed vs. Base vs. Fine-Tuned) for the target basin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZFZoXFEzKic"
   },
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oQAXWhpgzKid"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Optional, Tuple, Set\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Third-Party Library Imports\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgpd\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mipywidgets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwidgets\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display, Markdown\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'geopandas'"
     ]
    }
   ],
   "source": [
    "# Standard Library Imports\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import sys\n",
    "import yaml\n",
    "from typing import Any, Dict, List, Optional, Tuple, Set\n",
    "\n",
    "# Third-Party Library Imports\n",
    "import geopandas as gpd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "from ipywidgets import interactive, VBox\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# Local tutorial Module Imports\n",
    "# import tutorial.metrics\n",
    "import metrics\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Npt3Yb4cZj5U"
   },
   "source": [
    "## 0. User-Defined Paths\n",
    "1.  **Set Shapefile Path:** Set the variables `SHAPEFILE_PATH` to your local Caravan shapefile directory.\n",
    "2.  **Set Model Run Directory:** Set the variable `MODEL_RUN_DIR` to your local model-run directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFzHRcwHStZJ"
   },
   "outputs": [],
   "source": [
    "# Define the path to the shapefile containing basin geometries.\n",
    "# This shapefile is used for plotting maps of basin locations and model skill.\n",
    "SHAPEFILE_PATH = '/home/gsnearing/data/Caravan-nc/shapefiles/camels/camels_basin_shapes.shx'\n",
    "\n",
    "# Path to a base directory containing one or more model run directories.\n",
    "# The code below will allow you to select which model run in this directory\n",
    "# you want to evalutate.\n",
    "MODEL_RUN_DIR = '/home/gsnearing/tutorial/model-runs/'\n",
    "\n",
    "# Path to the streamflow gauge data to use for model evaluation.\n",
    "# This directory must be in the Caravan format.\n",
    "# If None, will use the observation data contained in the model output files.\n",
    "EVALUATION_DATA_DIR = '/home/gsnearing/data/camels-updated-2025'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e88885de"
   },
   "source": [
    "## 1. Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGNH-O-NaA7o"
   },
   "source": [
    "### Choose Base Model\n",
    "\n",
    "**Select Base Model:** The interactive widget will ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170,
     "referenced_widgets": [
      "a0893d2b31ec45959b7ee0a4339a055d",
      "b7bb936a2236475fb53b10ba8b272c3b",
      "f0e91eaaf4924bf4b070b9bc3126eb65",
      "38072fe4e2cc48e78f9d16d61206bda7",
      "b1585ed723e14652bd834c6c5151a6f1",
      "7f9b7a3a8e154481ad00a3b65d7e1f7c",
      "ad09d71ed22e4f95966a273d28e697ea"
     ]
    },
    "id": "ykzxoSmSzKif",
    "outputId": "5d81919b-73cc-4b24-bb7c-43b8b59e7dd7"
   },
   "outputs": [],
   "source": [
    "# --- Configuration: Paths & Model Names ---\n",
    "\n",
    "# This cell handles finding available model run directories and allows the user\n",
    "# to interactively select the base model run directory using a dropdown widget.\n",
    "\n",
    "# The base directory to search for model runs is defined in the cell above (MODEL_RUN_DIR).\n",
    "\n",
    "def find_model_run_dirs(base_dir: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Finds directories containing a 'test/model_epoch*/test_results.p' file.\n",
    "    These directories are considered valid model run directories.\n",
    "\n",
    "    Args:\n",
    "        base_dir: The base directory to start searching from.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary mapping display names (relative paths from base_dir)\n",
    "        to the absolute paths of the valid model run directories.\n",
    "    \"\"\"\n",
    "    run_dirs = {}\n",
    "    print(f\"Searching for model run directories in: {base_dir}\")\n",
    "    # Use os.walk to traverse directories efficiently\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        # Check if a 'test' subdirectory exists within the current root\n",
    "        if 'test' in dirs:\n",
    "            test_dir = os.path.join(root, 'test')\n",
    "            # Check for subdirectories named 'model_epoch*' within the 'test' directory\n",
    "            epoch_dirs = glob.glob(os.path.join(test_dir, 'model_epoch*'))\n",
    "            for epoch_dir in epoch_dirs:\n",
    "                # Check if 'test_results.p' file exists within the 'model_epoch*' directory\n",
    "                if os.path.isfile(os.path.join(epoch_dir, 'test_results.p')):\n",
    "                    # Create a user-friendly display name for the run\n",
    "                    # This is the path relative to the initial search base_dir\n",
    "                    display_name = os.path.relpath(root, base_dir)\n",
    "                    run_dirs[display_name] = root\n",
    "                    # Since we found a test_results.p for this run, we don't need\n",
    "                    # to search deeper into its subdirectories.\n",
    "                    break # Found a result file in an epoch dir within this run\n",
    "    return run_dirs\n",
    "\n",
    "# Find available run directories using the path set in the cell above\n",
    "available_run_dirs = find_model_run_dirs(MODEL_RUN_DIR)\n",
    "\n",
    "# Check if any run directories were found\n",
    "if not available_run_dirs:\n",
    "    print(\"\\nError: No model run directories containing test results found.\")\n",
    "    print(f\"Please ensure MODEL_RUN_DIR ({MODEL_RUN_DIR}) is set correctly and contains valid runs.\")\n",
    "    # You might want to exit or disable further processing here if no runs are found\n",
    "else:\n",
    "    print(f\"\\nFound {len(available_run_dirs)} potential model run directories.\")\n",
    "    # print(\"Available runs:\", list(available_run_dirs.keys())) # Uncomment for debugging if needed\n",
    "\n",
    "    # --- Interactive Selection ---\n",
    "    # Define the function that will be called when the dropdown value changes\n",
    "    def select_base_model(base_model_selection):\n",
    "        \"\"\"\n",
    "        Sets the global variables for the selected base model run directory and name.\n",
    "        Performs basic validation.\n",
    "        \"\"\"\n",
    "        global base_model_run_dir, base_model_name\n",
    "\n",
    "        # Get the absolute path for the selected run directory\n",
    "        base_model_run_dir = available_run_dirs.get(base_model_selection)\n",
    "        # Create a display name for the selected base model\n",
    "        base_model_name = f'Base Model ({base_model_selection})'\n",
    "\n",
    "        # --- Validation Checks ---\n",
    "        # Check if the selected base model directory is valid\n",
    "        if not base_model_run_dir or not os.path.isdir(base_model_run_dir):\n",
    "            print(f\"\\nError: Base model directory not found or invalid: {base_model_selection}\")\n",
    "\n",
    "        # Print the configuration that has been set\n",
    "        print(\"\\nConfiguration set:\")\n",
    "        print(f\"  Base Model: {base_model_name} ({base_model_run_dir})\")\n",
    "\n",
    "\n",
    "    # Create a dropdown widget for selecting the base model\n",
    "    run_dir_options = sorted(available_run_dirs.keys()) # Sort options alphabetically\n",
    "    base_dropdown = widgets.Dropdown(\n",
    "        options=run_dir_options, # Use the found run directories as options\n",
    "        description='Select Base Model:', # Label for the dropdown\n",
    "        disabled=False, # The widget should be enabled\n",
    "        style = {'description_width': 'initial'} # Adjust description width for better display\n",
    "    )\n",
    "\n",
    "    # Create an interactive widget linking the dropdown to the selection function\n",
    "    # The output of the function (print statements) will appear below the widget\n",
    "    interactive_selection = interactive(\n",
    "        select_base_model,\n",
    "        base_model_selection=base_dropdown, # Link the dropdown widget to the function argument\n",
    "    )\n",
    "\n",
    "    # Display the interactive widget\n",
    "    display(interactive_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bf7d54f2"
   },
   "source": [
    "### Visualize Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "new_cell_config_load_code",
    "outputId": "69e7ba0a-b809-4acc-b3a1-e08a1c7dd450"
   },
   "outputs": [],
   "source": [
    "def read_basin_list(file_path: str) -> Set[str]:\n",
    "    \"\"\"Reads a basin list file and returns a set of normalized basin IDs.\"\"\"\n",
    "    if not os.path.isfile(file_path):\n",
    "        print(f\"Warning: Basin file not found: {file_path}\")\n",
    "        return set()\n",
    "    with open(file_path, 'r') as f:\n",
    "        # Read lines, strip whitespace, and normalize the ID\n",
    "        # Assumes IDs might be like 'camels_012345' and we just want '012345'\n",
    "        ids = [normalize_id(line.strip()) for line in f if line.strip()]\n",
    "    return set(ids)\n",
    "\n",
    "def normalize_id(basin_id: str) -> str:\n",
    "    \"\"\"Converts basin IDs to a standard string format for comparison.\"\"\"\n",
    "    # Example: 'camels_012345' -> '012345'\n",
    "    # Example: 12345 -> '012345' (if it's a CAMELS ID, they are often 8-digit strings)\n",
    "    # This function MUST match the format in your shapefile ID column\n",
    "    str_id = str(basin_id).split('_')[-1]\n",
    "    # Assuming CAMELS-style 8-digit zero-padding\n",
    "    return str_id.zfill(8)\n",
    "\n",
    "base_config_path = os.path.join(base_model_run_dir, 'config.yml')\n",
    "train_basin_ids = set()\n",
    "test_basin_ids = set()\n",
    "\n",
    "try:\n",
    "    with open(base_config_path, 'r') as f:\n",
    "        base_config = yaml.safe_load(f)\n",
    "\n",
    "    train_basin_file = base_config.get('train_basin_file')\n",
    "    test_basin_file = base_config.get('test_basin_file')\n",
    "\n",
    "    if train_basin_file:\n",
    "        print(f\"Found train basin file: {train_basin_file}\")\n",
    "        train_basin_ids = read_basin_list(train_basin_file)\n",
    "        print(f\"Loaded {len(train_basin_ids)} training basin IDs.\")\n",
    "    else:\n",
    "        print(\"Warning: 'train_basin_file' not found in config.yml\")\n",
    "\n",
    "    if test_basin_file:\n",
    "        print(f\"Found test basin file: {test_basin_file}\")\n",
    "        test_basin_ids = read_basin_list(test_basin_file)\n",
    "        print(f\"Loaded {len(test_basin_ids)} test basin IDs.\")\n",
    "    else:\n",
    "        print(\"Warning: 'test_basin_file' not found in config.yml\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: config.yml not found in {base_model_run_dir}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error reading config.yml: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lnrf6nhPEyPY"
   },
   "outputs": [],
   "source": [
    "gdf_all_basins = gpd.read_file(SHAPEFILE_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aac91798"
   },
   "source": [
    "### Simplify Basin Geometries (Optional)\n",
    "\n",
    "If plotting the shapefile is causing performance issues or crashes, you can try simplifying the basin geometries. This reduces the number of vertices in each polygon, making them less complex to render. The `simplify` method from GeoPandas is used here with a `tolerance` parameter that controls the degree of simplification. A larger tolerance results in more aggressive simplification. You may need to adjust the `tolerance` value depending on your data and desired level of detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84c0d9fa",
    "outputId": "204b41a2-0407-4fac-977f-3317fda6479e"
   },
   "outputs": [],
   "source": [
    "# Add a simplification step before plotting if needed\n",
    "# Adjust the tolerance value to control the degree of simplification\n",
    "# A larger tolerance means more simplification.\n",
    "try:\n",
    "    # Check if gdf_all_basins exists and is not None\n",
    "    if 'gdf_all_basins' in locals() and gdf_all_basins is not None:\n",
    "        # Simplify the geometries\n",
    "        gdf_all_basins['geometry'] = gdf_all_basins['geometry'].simplify(tolerance=0.01, preserve_topology=True)\n",
    "        print(\"Basin geometries simplified for plotting.\")\n",
    "    else:\n",
    "        print(\"GeoDataFrame not loaded. Skipping simplification.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error simplifying geometries: {e}\")\n",
    "    print(\"Proceeding with original geometries.\")\n",
    "\n",
    "# Now execute the plotting cell (new_cell_basin_map_code)\n",
    "# You might need to manually run the plotting cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gl7mahQaFsci"
   },
   "outputs": [],
   "source": [
    "# Plot the geometry of the first basin\n",
    "gdf_all_basins.iloc[[0]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tq6ixUp2E05o"
   },
   "outputs": [],
   "source": [
    "asdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldvuS8bI63iY"
   },
   "source": [
    "### Plot Train & Test Basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "new_cell_basin_map_code"
   },
   "outputs": [],
   "source": [
    "# Ensure geopandas is imported\n",
    "import geopandas as gpd\n",
    "\n",
    "shapefile_basin_id_column='gauge_id'\n",
    "\n",
    "def plot_colored_shapefile(\n",
    "    gdf: gpd.GeoDataFrame,\n",
    "    column: str,\n",
    "    title: str,\n",
    "    legend_title: str,\n",
    "    cmap: Optional[str] = None,\n",
    "    colors: Optional[Dict[Any, str]] = None,\n",
    "    # add_basemap: bool = True, # Removed contextily dependency\n",
    "    figsize: Tuple[int, int] = (12, 12),\n",
    "    missing_kwds: Optional[Dict[str, Any]] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots a GeoDataFrame with polygons colored based on a specified column.\n",
    "\n",
    "    Args:\n",
    "        gdf: The GeoDataFrame to plot.\n",
    "        column: The name of the column in the GeoDataFrame to use for coloring.\n",
    "        title: The title of the plot.\n",
    "        legend_title: The title for the legend.\n",
    "        cmap: Colormap name (if using continuous data).\n",
    "        colors: Dictionary mapping unique values in 'column' to specific colors.\n",
    "                Overrides cmap if provided.\n",
    "        # add_basemap: Whether to add a contextily basemap. # Removed contextily dependency\n",
    "        figsize: Figure size.\n",
    "        missing_kwds: Dictionary of keyword arguments for handling missing values\n",
    "                      (e.g., {'color': 'lightgrey', 'label': 'No Data'}).\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    if colors:\n",
    "        # Plot using specific colors for categories\n",
    "        for category, color in colors.items():\n",
    "            subset = gdf_to_plot[gdf_to_plot[column] == category]\n",
    "            if not subset.empty:\n",
    "                 subset.plot(\n",
    "                    ax=ax,\n",
    "                    color=color,\n",
    "                    label=category,\n",
    "                    alpha=0.7,\n",
    "                    edgecolor='black',\n",
    "                    linewidth=0.5\n",
    "                )\n",
    "            return\n",
    "\n",
    "    else:\n",
    "        # Plot using colormap\n",
    "        gdf_to_plot.plot(\n",
    "            ax=ax,\n",
    "            column=column,\n",
    "            legend=True,\n",
    "            legend_kwds={'title': legend_title},\n",
    "            cmap=cmap,\n",
    "            alpha=0.7,\n",
    "            edgecolor='black',\n",
    "            linewidth=0.5,\n",
    "            missing_kwds=missing_kwds\n",
    "        )\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_axis_off()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Apply the function to plot train/test basins ---\n",
    "\n",
    "# Read the shapefile\n",
    "gdf_all_basins = gpd.read_file(SHAPEFILE_PATH)\n",
    "\n",
    "# Ensure the comparison column exists\n",
    "if shapefile_basin_id_column not in gdf_all_basins.columns:\n",
    "    raise KeyError(f\"ID column '{shapefile_basin_id_column}' not found in shapefile. Available columns: {gdf_all_basins.columns}\")\n",
    "\n",
    "# Normalize the ID column in the shapefile for comparison\n",
    "gdf_all_basins['normalized_id'] = gdf_all_basins[shapefile_basin_id_column].apply(normalize_id)\n",
    "\n",
    "is_train = gdf_all_basins['normalized_id'].isin(train_basin_ids)\n",
    "is_test = gdf_all_basins['normalized_id'].isin(test_basin_ids)\n",
    "\n",
    "# Assign categories\n",
    "gdf_all_basins['dataset'] = 'Not Used'\n",
    "gdf_all_basins.loc[is_train, 'dataset'] = 'Train Only'\n",
    "gdf_all_basins.loc[is_test, 'dataset'] = 'Test Only'\n",
    "gdf_all_basins.loc[is_train & is_test, 'dataset'] = 'Train & Test'\n",
    "\n",
    "# Define colors for each category\n",
    "dataset_colors = {\n",
    "    'Train Only': 'blue',\n",
    "    'Test Only': 'red',\n",
    "    'Train & Test': 'purple',\n",
    "    'Not Used': 'lightgrey'\n",
    "}\n",
    "\n",
    "# Plot using the reusable function\n",
    "plot_colored_shapefile(\n",
    "    gdf=gdf_all_basins,\n",
    "    column='dataset',\n",
    "    title=f\"Train & Test Basin Sets from {base_model_name if 'base_model_name' in globals() else 'Base Model'}\",\n",
    "    legend_title='Basin Set',\n",
    "    colors=dataset_colors,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qcGToAZ7CPG-"
   },
   "outputs": [],
   "source": [
    "asdfadsfasdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsEUzNAwzKig"
   },
   "source": [
    "## 5. Load Model Results\n",
    "\n",
    "This section finds and loads the `test_results.p` file from both your base model and fine-tuned model directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "61FVOQz5zKih"
   },
   "outputs": [],
   "source": [
    "def load_test_results(run_dir: str) -> Tuple[Optional[Dict[str, Any]], Optional[int]]:\n",
    "    \"\"\"\n",
    "    Finds and loads the 'test_results.p' file from a specific model run directory.\n",
    "\n",
    "    Args:\n",
    "        run_dir: The specific model run directory (e.g., .../camels-2014-run).\n",
    "\n",
    "    Returns:\n",
    "        A tuple of (data, epoch_number). 'data' is the loaded pickle file (a dict).\n",
    "    \"\"\"\n",
    "    search_path = os.path.join(run_dir, 'test', 'model_epoch*', 'test_results.p')\n",
    "    result_files = glob.glob(search_path)\n",
    "\n",
    "    if not result_files:\n",
    "        print(f\"Warning: No 'test_results.p' file found in {run_dir}/test/model_epoch*/\")\n",
    "        return None, None\n",
    "\n",
    "    if len(result_files) > 1:\n",
    "        print(f\"Warning: Multiple 'test_results.p' files found. Using the first one: {result_files[0]}\")\n",
    "\n",
    "    file_path = result_files[0]\n",
    "\n",
    "    # Try to extract epoch number\n",
    "    epoch_number = 0\n",
    "    match = re.search(r'model_epoch(\\d+)', file_path)\n",
    "    if match:\n",
    "        epoch_number = int(match.group(1))\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        print(f\"Successfully loaded results from: {file_path}\")\n",
    "        return data, epoch_number\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# --- Execute Data Loading ---\n",
    "print(f\"Loading base model results for: {base_model_name}\")\n",
    "base_model_data, base_model_epoch = load_test_results(base_model_run_dir)\n",
    "\n",
    "print(f\"\\nLoading fine-tuned model results for: {finetune_model_name}\")\n",
    "finetune_model_data, finetune_model_epoch = load_test_results(finetune_model_run_dir)\n",
    "\n",
    "if base_model_data is None or finetune_model_data is None:\n",
    "    print(\"\\nError: Failed to load one or both model results. Please check paths.\")\n",
    "else:\n",
    "    print(\"\\nAll model results loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rhYOJEazKij"
   },
   "source": [
    "## 6. Analysis & Plotting Functions\n",
    "\n",
    "Below are the core helper functions we will use for our analysis. We define them all here in one place so they can be called later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dambrsu0zKik"
   },
   "outputs": [],
   "source": [
    "def calculate_metrics_by_lead_time(gauge_data: Dict[str, Any]) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Calculates metrics for a single gauge for each lead time.\n",
    "    Assumes 'metrics.py' is imported and available.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        obs_dataarray = gauge_data['1D']['xr']['streamflow_obs']\n",
    "        sim_dataarray = gauge_data['1D']['xr']['streamflow_sim']\n",
    "    except KeyError as e:\n",
    "        print(f\"Warning: Data structure unexpected. Missing key {e}. Skipping metric calculation.\")\n",
    "        return None\n",
    "    except TypeError:\n",
    "        print(f\"Warning: gauge_data is not in the expected format. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        metrics_list = metrics.get_available_metrics()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Could not get metrics list from metrics.py: {e}\")\n",
    "        print(\"Defaulting to KGE and NSE.\")\n",
    "        metrics_list = ['KGE', 'NSE']\n",
    "\n",
    "    lead_times = obs_dataarray['time_step'].values\n",
    "    metrics_results = {}\n",
    "\n",
    "    for lt in lead_times:\n",
    "        obs_at_lead_time = obs_dataarray.sel(time_step=lt)\n",
    "        sim_at_lead_time = sim_dataarray.sel(time_step=lt)\n",
    "\n",
    "        try:\n",
    "            calculated_metrics = metrics.calculate_metrics(\n",
    "                obs_at_lead_time,\n",
    "                sim_at_lead_time,\n",
    "                metrics=metrics_list,\n",
    "                resolution=\"1D\",\n",
    "                datetime_coord=\"date\"\n",
    "            )\n",
    "            metrics_results[lt] = calculated_metrics\n",
    "        except Exception as e:\n",
    "            # print(f\"Could not calculate metrics for lead time {lt}: {e}\")\n",
    "            metrics_results[lt] = {m: np.nan for m in metrics_list}\n",
    "\n",
    "    metrics_df = pd.DataFrame.from_dict(metrics_results, orient='index')\n",
    "    metrics_df.index.name = 'lead_time'\n",
    "    return metrics_df\n",
    "\n",
    "def calculate_metrics_for_run(run_data: Dict[str, Any]) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Iterates through all gauges in a loaded run and calculates metrics for each.\n",
    "\n",
    "    Args:\n",
    "        run_data: The loaded test_results.p dictionary {gauge_id: data}.\n",
    "\n",
    "    Returns:\n",
    "        A nested dictionary: {gauge_id: pd.DataFrame_of_metrics}\n",
    "    \"\"\"\n",
    "    all_metrics_results = {}\n",
    "    if not run_data:\n",
    "        print(\"No run data provided. Skipping metric calculation.\")\n",
    "        return all_metrics_results\n",
    "\n",
    "    for gauge_id, gauge_data in run_data.items():\n",
    "        metrics_df = calculate_metrics_by_lead_time(gauge_data)\n",
    "        if metrics_df is not None:\n",
    "            all_metrics_results[gauge_id] = metrics_df\n",
    "\n",
    "    print(f\"Metric calculation complete for {len(all_metrics_results)} gauges.\")\n",
    "    return all_metrics_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xC7x2WvzKim"
   },
   "source": [
    "## 7. Pre-calculate All Metrics\n",
    "\n",
    "To make the plots fast and responsive, we will pre-calculate the metrics for *every* loaded model and basin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1zOhdKv7zKim"
   },
   "outputs": [],
   "source": [
    "if base_model_data and finetune_model_data:\n",
    "    print(f\"Calculating metrics for: {base_model_name}\")\n",
    "    base_model_metrics = calculate_metrics_for_run(base_model_data)\n",
    "\n",
    "    print(f\"\\nCalculating metrics for: {finetune_model_name}\")\n",
    "    finetune_model_metrics = calculate_metrics_for_run(finetune_model_data)\n",
    "\n",
    "    # --- Identify the fine-tuned basin ---\n",
    "    if len(finetune_model_metrics) != 1:\n",
    "        print(f\"Warning: Fine-tuned model has {len(finetune_model_metrics)} basins. Expected 1.\")\n",
    "\n",
    "    finetune_basin_id = list(finetune_model_metrics.keys())[0]\n",
    "    print(f\"\\nFine-tuning basin identified as: {finetune_basin_id}\")\n",
    "\n",
    "    # --- Create a combined DataFrame for all base model basins ---\n",
    "    try:\n",
    "        base_model_all_basins_df = pd.concat(\n",
    "            base_model_metrics.values(),\n",
    "            keys=base_model_metrics.keys(),\n",
    "            names=['basin_id', 'lead_time']\n",
    "        )\n",
    "        print(\"Created combined DataFrame for all base model basins.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not create combined DataFrame: {e}\")\n",
    "        base_model_all_basins_df = None\n",
    "\n",
    "else:\n",
    "    print(\"Model data not loaded. Skipping metric calculation.\")\n",
    "    base_model_metrics = {}\n",
    "    finetune_model_metrics = {}\n",
    "    base_model_all_basins_df = None\n",
    "    finetune_basin_id = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "new_cell_skill_map"
   },
   "source": [
    "## 8. Base Model Skill Map\n",
    "\n",
    "This map shows the performance of your base model across all test basins. Basins are color-coded by their KGE skill at lead time 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "new_cell_skill_map_code"
   },
   "outputs": [],
   "source": [
    "if not gpd_available:\n",
    "    print(\"Geospatial libraries not found. Skipping skill map.\")\n",
    "elif base_model_all_basins_df is None:\n",
    "    print(\"Base model metrics not calculated. Skipping skill map.\")\n",
    "else:\n",
    "    print(\"Plotting base model skill map...\")\n",
    "    try:\n",
    "        SKILL_METRIC = 'KGE'\n",
    "        SKILL_LEAD_TIME = 0\n",
    "\n",
    "        # Get skills for the specified lead time\n",
    "        skills = base_model_all_basins_df.xs(SKILL_LEAD_TIME, level='lead_time')[SKILL_METRIC]\n",
    "        skills.name = f'{SKILL_METRIC} (Lead Time {SKILL_LEAD_TIME})'\n",
    "        skills_df = skills.reset_index()\n",
    "\n",
    "        # Normalize basin IDs for merging\n",
    "        skills_df['normalized_id'] = skills_df['basin_id'].apply(normalize_id)\n",
    "\n",
    "        # Load shapefile again (or reuse if available)\n",
    "        if 'gdf_all_basins' not in locals():\n",
    "             gdf_all_basins = gpd.read_file(shapefile_path)\n",
    "             gdf_all_basins['normalized_id'] = gdf_all_basins[shapefile_basin_id_column].apply(normalize_id)\n",
    "\n",
    "        # Merge skills with geometry\n",
    "        gdf_with_skills = gdf_all_basins.merge(skills_df, on='normalized_id')\n",
    "\n",
    "        if gdf_with_skills.empty:\n",
    "            print(\"No matching basins found between metrics and shapefile. Check ID formats.\")\n",
    "        else:\n",
    "            # Create the plot\n",
    "            fig, ax = plt.subplots(figsize=(12, 12))\n",
    "            gdf_with_skills_web = gdf_with_skills.to_crs(epsg=3857) # Reproject\n",
    "\n",
    "            gdf_with_skills_web.plot(\n",
    "                ax=ax,\n",
    "                column=skills.name,\n",
    "                legend=True,\n",
    "                legend_kwds={'label': f'{SKILL_METRIC} Score', 'orientation': 'horizontal'},\n",
    "                cmap='viridis',\n",
    "                alpha=0.8,\n",
    "                edgecolor='black',\n",
    "                linewidth=0.5,\n",
    "                missing_kwds={'color': 'lightgrey', 'label': 'No Data'}\n",
    "            )\n",
    "\n",
    "            ctx.add_basemap(ax, source=ctx.providers.Stamen.Terrain, zoom=6)\n",
    "            ax.set_title(f\"{base_model_name} Performance: {skills.name}\")\n",
    "            ax.set_axis_off()\n",
    "            plt.show()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Shapefile not found at: {shapefile_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during skill map plotting: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "new_cell_skill_table"
   },
   "source": [
    "## 9. Base Model Skills (Table)\n",
    "\n",
    "This table shows the basin IDs and their corresponding skill scores for the metric and lead time plotted above, sorted from best to worst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "new_cell_skill_table_code"
   },
   "outputs": [],
   "source": [
    "if 'skills' in locals():\n",
    "    print(f\"Displaying skills for: {skills.name}\")\n",
    "    display(skills.reset_index().sort_values(by=skills.name, ascending=False).set_index('basin_id'))\n",
    "else:\n",
    "    print(\"Skills data not available to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "new_cell_interactive_skill"
   },
   "source": [
    "## 10. Fine-Tuning Comparison: Skill vs. Lead Time\n",
    "\n",
    "This is the key comparison plot. Use the dropdown to select a metric.\n",
    "\n",
    "-   **Lines:** Show the performance of the **Base Model** (blue) and the **Fine-Tuned Model** (orange) for the target basin.\n",
    "-   **Box Plots (Background):** Show the distribution (median, quartiles) of that metric for *all other basins* in the base model's test set. This tells you if the base model was already performing well or poorly for this basin compared to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "new_cell_interactive_skill_code"
   },
   "outputs": [],
   "source": [
    "if not finetune_basin_id:\n",
    "    display(Markdown(\"**Error: Could not identify fine-tuning basin. Cannot create comparison plot.**\"))\n",
    "elif finetune_basin_id not in base_model_metrics:\n",
    "    display(Markdown(f\"**Error: Fine-tuning basin '{finetune_basin_id}' not found in base model results. Cannot compare.**\"))\n",
    "else:\n",
    "    # Get metrics for the specific fine-tuned basin\n",
    "    ft_basin_base_metrics = base_model_metrics[finetune_basin_id]\n",
    "    ft_basin_finetune_metrics = finetune_model_metrics[finetune_basin_id]\n",
    "\n",
    "    # Get metrics for all OTHER basins from the base model\n",
    "    other_basins_base_metrics = base_model_all_basins_df.drop(finetune_basin_id, level='basin_id')\n",
    "\n",
    "    def plot_finetune_comparison(metric_name):\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        ax = plt.gca()\n",
    "\n",
    "        # 1. Plot background boxplots for all OTHER basins\n",
    "        try:\n",
    "            # Unstack to get lead_time x basin_id\n",
    "            boxplot_data_all = other_basins_base_metrics.unstack(level='basin_id')[metric_name]\n",
    "\n",
    "            # Create a list of arrays, one for each lead time, dropping NaNs\n",
    "            boxplot_data = [col.dropna().values for _, col in boxplot_data_all.items()]\n",
    "            lead_times = boxplot_data_all.index\n",
    "\n",
    "            ax.boxplot(\n",
    "                boxplot_data,\n",
    "                positions=lead_times,\n",
    "                patch_artist=True,\n",
    "                showfliers=False,\n",
    "                widths=0.6,\n",
    "                boxprops=dict(facecolor='lightgray', alpha=0.7),\n",
    "                whiskerprops=dict(color='gray'),\n",
    "                capprops=dict(color='gray'),\n",
    "                medianprops=dict(color='black')\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Could not plot boxplot background: {e}\")\n",
    "\n",
    "        # 2. Plot lines for the target basin\n",
    "        base_line = ft_basin_base_metrics[metric_name]\n",
    "        ft_line = ft_basin_finetune_metrics[metric_name]\n",
    "\n",
    "        ax.plot(base_line.index, base_line.values, label=base_model_name, marker='o', lw=2, zorder=10)\n",
    "        ax.plot(ft_line.index, ft_line.values, label=finetune_model_name, marker='s', lw=2, zorder=10)\n",
    "\n",
    "        # Add a dummy artist for the boxplot legend\n",
    "        ax.add_patch(plt.Rectangle((0,0), 1, 1, fc='lightgray', alpha=0.7, label='Base Model (All Other Basins)'))\n",
    "\n",
    "        ax.set_title(f\"{metric_name} vs. Lead Time for Basin {finetune_basin_id}\")\n",
    "        ax.set_xlabel(\"Lead Time (days)\")\n",
    "        ax.set_ylabel(f\"{metric_name} Score\")\n",
    "        ax.legend()\n",
    "        ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        ax.set_xticks(lead_times)\n",
    "        plt.show()\n",
    "\n",
    "    # --- Create Widget ---\n",
    "    available_metrics = list(ft_basin_base_metrics.columns)\n",
    "    metric_widget = widgets.Dropdown(\n",
    "        options=available_metrics,\n",
    "        value='KGE' if 'KGE' in available_metrics else available_metrics[0],\n",
    "        description='Metric:',\n",
    "        disabled=False,\n",
    "    )\n",
    "\n",
    "    display(interactive(plot_finetune_comparison, metric_name=metric_widget))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "new_cell_interactive_hydrograph"
   },
   "source": [
    "## 11. Fine-Tuning Comparison: Hydrographs\n",
    "\n",
    "This plot lets you visually inspect the hydrographs for the fine-tuned basin. Use the sliders and text boxes to select the lead time and date range you want to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "new_cell_interactive_hydrograph_code"
   },
   "outputs": [],
   "source": [
    "if not finetune_basin_id:\n",
    "    display(Markdown(\"**Error: Could not identify fine-tuning basin. Cannot create hydrograph plot.**\"))\n",
    "elif (finetune_basin_id not in base_model_data) or (finetune_basin_id not in finetune_model_data):\n",
    "    display(Markdown(f\"**Error: Data for basin '{finetune_basin_id}' not found in both models. Cannot compare.**\"))\n",
    "else:\n",
    "    # Get max lead time\n",
    "    try:\n",
    "        max_lt = int(base_model_data[finetune_basin_id]['1D']['xr']['time_step'].max())\n",
    "    except:\n",
    "        max_lt = 10 # default\n",
    "\n",
    "    def plot_comparison_hydrograph(lead_time, start_date_str, end_date_str):\n",
    "        try:\n",
    "            # Slice by date\n",
    "            data_slice = slice(start_date_str, end_date_str)\n",
    "        except Exception as e:\n",
    "            print(f\"Invalid date format. Using full range. Error: {e}\")\n",
    "            data_slice = slice(None, None)\n",
    "\n",
    "        try:\n",
    "            # Get data arrays for the fine-tuned basin from both models\n",
    "            obs_da = base_model_data[finetune_basin_id]['1D']['xr']['streamflow_obs']\n",
    "            base_sim_da = base_model_data[finetune_basin_id]['1D']['xr']['streamflow_sim']\n",
    "            ft_sim_da = finetune_model_data[finetune_basin_id]['1D']['xr']['streamflow_sim']\n",
    "\n",
    "            # Select lead time and date range, drop NaNs from obs\n",
    "            obs_lt = obs_da.sel(time_step=lead_time, date=data_slice).dropna(dim='date')\n",
    "            if obs_lt.size == 0:\n",
    "                print(f\"No observed data for basin {finetune_basin_id} in this date range.\")\n",
    "                return\n",
    "\n",
    "            # Align sim data to the valid observation dates\n",
    "            base_sim_lt = base_sim_da.sel(time_step=lead_time).reindex(date=obs_lt['date'])\n",
    "            ft_sim_lt = ft_sim_da.sel(time_step=lead_time).reindex(date=obs_lt['date'])\n",
    "\n",
    "            # --- Plotting ---\n",
    "            plt.figure(figsize=(15, 7))\n",
    "            plt.plot(obs_lt['date'], obs_lt.values, label='Observed', color='black', lw=2.5)\n",
    "            plt.plot(base_sim_lt['date'], base_sim_lt.values, label=base_model_name, linestyle='--', alpha=0.8)\n",
    "            plt.plot(ft_sim_lt['date'], ft_sim_lt.values, label=finetune_model_name, linestyle='-', alpha=0.8)\n",
    "\n",
    "            plt.title(f'Hydrograph for {finetune_basin_id} (Lead Time {lead_time} days)')\n",
    "            plt.xlabel('Date')\n",
    "            plt.ylabel('Streamflow')\n",
    "            plt.legend()\n",
    "            plt.grid(True, linestyle='--', alpha=0.6)\n",
    "            plt.show()\n",
    "\n",
    "        except KeyError as e:\n",
    "            print(f\"Error: Data structure missing. Could not find key: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during plotting: {e}\")\n",
    "\n",
    "    # --- Create Widgets ---\n",
    "    lead_time_widget = widgets.IntSlider(\n",
    "        value=0, min=0, max=max_lt, step=1, description='Lead Time (days):'\n",
    "    )\n",
    "    start_date_widget = widgets.Text(value='2022-01-01', description='Start Date:')\n",
    "    end_date_widget = widgets.Text(value='2022-03-01', description='End Date:')\n",
    "\n",
    "    ui = VBox([lead_time_widget, start_date_widget, end_date_widget])\n",
    "    out = interactive(\n",
    "        plot_comparison_hydrograph,\n",
    "        lead_time=lead_time_widget,\n",
    "        start_date_str=start_date_widget,\n",
    "        end_date_str=end_date_widget\n",
    "    )\n",
    "    display(ui, out.children[-1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "38072fe4e2cc48e78f9d16d61206bda7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f9b7a3a8e154481ad00a3b65d7e1f7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "description_width": "initial"
     }
    },
    "a0893d2b31ec45959b7ee0a4339a055d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [
       "widget-interact"
      ],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b7bb936a2236475fb53b10ba8b272c3b",
       "IPY_MODEL_f0e91eaaf4924bf4b070b9bc3126eb65"
      ],
      "layout": "IPY_MODEL_38072fe4e2cc48e78f9d16d61206bda7",
      "tabbable": null,
      "tooltip": null
     }
    },
    "ad09d71ed22e4f95966a273d28e697ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1585ed723e14652bd834c6c5151a6f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7bb936a2236475fb53b10ba8b272c3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "3-basin-example_2610_143234",
       "3-basin-example_2610_143234/finetune-3-basin-example-camels-06468250_2610_155959",
       "camels/camels-530-2014_2610_113135"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "DropdownView",
      "description": "Select Base Model:",
      "description_allow_html": false,
      "disabled": false,
      "index": 0,
      "layout": "IPY_MODEL_b1585ed723e14652bd834c6c5151a6f1",
      "style": "IPY_MODEL_7f9b7a3a8e154481ad00a3b65d7e1f7c",
      "tabbable": null,
      "tooltip": null
     }
    },
    "f0e91eaaf4924bf4b070b9bc3126eb65": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_ad09d71ed22e4f95966a273d28e697ea",
      "msg_id": "",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "\n",
         "Configuration set:\n",
         "  Base Model: Base Model (3-basin-example_2610_143234) (/home/gsnearing/tutorial/model-runs/3-basin-example_2610_143234)\n"
        ]
       }
      ],
      "tabbable": null,
      "tooltip": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
