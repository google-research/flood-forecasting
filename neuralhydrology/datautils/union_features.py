from typing import Dict

import numpy as np
import xarray as xr


def _expand_lead_times(da: xr.DataArray, lead_times: np.ndarray) -> xr.DataArray:
    if 'lead_time' in da.dims:
        raise ValueError('Trying to expand a dataarray that already has a lead time.')
    # TODO (future) :: This assumes daily data.
    lt_das = (da.shift(date=-int(lt / np.timedelta64(1, "D"))) for lt in lead_times)
    lt_da = xr.concat(lt_das, dim="lead_time")
    return lt_da.assign_coords(lead_time=lead_times)


def _union_features_with_same_dimensions(
  feature_da: xr.DataArray,
  mask_feature_da: xr.DataArray,
) -> xr.DataArray:
    """Mask one feature with another when both are the same size."""
    return feature_da.combine_first(mask_feature_da)


def _union_lead_time_feature_with_non_lead_time_feature(
  feature_da: xr.DataArray,
  mask_feature_da: xr.DataArray,
) -> xr.DataArray:
    """Mask a lead-time feature with a non-lead-time feature."""
    lead_times = feature_da.coords["lead_time"].values
    lt_mask_da = _expand_lead_times(mask_feature_da, lead_times)
    return _union_features_with_same_dimensions(feature_da, lt_mask_da)


def _union_non_lead_time_feature_with_lead_time_feature(
  feature_da: xr.DataArray,
  mask_feature_da: xr.DataArray,
) -> xr.DataArray:
    """Mask a non-lead-time feature with the earliest forecast from a lead-time feature."""
    min_lead_time = mask_feature_da["lead_time"].min().item()
    min_lead_time_mask_feature = mask_feature_da.sel(lead_time=min_lead_time, drop=True)
    shift_days = int(min_lead_time / np.timedelta64(1, "D"))
    # Align mask's issue date with feature's valid date via shift forward by min lead time.
    mask_values = min_lead_time_mask_feature.shift(date=shift_days)
    return _union_features_with_same_dimensions(feature_da, mask_values)


def union_features(
    dataset: xr.Dataset,
    union_feature_mapping: Dict[str, str]
) -> xr.Dataset:
    """Replace missing values in various features with values from another feature.
    
    Works with features that do and do not have a `lead_time` dimension.
    
    Parameters
    ----------
    dataset : xr.Dataset
        Dataset of features to be masked *and* features used for masking.
    union_feature_mapping : Dict[str, str]
        A 1-to-1 mapping from a feature that will be masked by another feature. 
    
    Returns
    -------
    Dataset of all features from the original dataset where the features that are keys in `union_feature_mapping'
        are masked by the features in their respective dictionary values.
    
    Raises
    ------
    ValueError if a masking feature is not found.
    """
    masked_das = []

    # Keep track of features that have been explicitly processed (i.e., were the 'feature' key)
    processed_feature_names = set()

    for feature, mask_feature in union_feature_mapping.items():

        # Don't bother masking a feature with itself.
        if feature == mask_feature:
            masked_das.append(dataset[feature])
        # We don't care if a feature is not present.
        if feature not in dataset.data_vars:
            continue
        # We DO care if a masking feature is not present because the user might not notice
        # and believe it was masked.
        if mask_feature not in dataset.data_vars:
            raise ValueError(f'Masking feature {mask_feature} not in dataset.')
        
        # Mask the feature depending on their dimensions.
        feature_da = dataset[feature]
        mask_feature_da = dataset[mask_feature]
        
        if 'lead_time' in feature_da.dims and 'lead_time' not in mask_feature_da.dims:
            masked_das.append(
                _union_lead_time_feature_with_non_lead_time_feature(
                    feature_da=feature_da,
                    mask_feature_da=mask_feature_da
                )
            )

        elif 'lead_time' not in feature_da.dims and 'lead_time' in mask_feature_da.dims:
            masked_das.append(
                _union_non_lead_time_feature_with_lead_time_feature(
                    feature_da=feature_da,
                    mask_feature_da=mask_feature_da
                )
            )

        else:
            masked_das.append(
                _union_features_with_same_dimensions(
                    feature_da=feature_da,
                    mask_feature_da=mask_feature_da
                )
            )

    # Collect all features from the original dataset that were NOT targets of a union operation.
    # These should be included in the final output as they were.
    for original_feature_name in dataset.data_vars:
        if original_feature_name not in processed_feature_names:
            masked_das.append(dataset[original_feature_name])

    # Concatenate everything back into a single dataset.
    return xr.merge(masked_das)